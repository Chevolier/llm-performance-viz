{
  "aws_ec2_prices": {
    "g6e.2xlarge": 2.24208,
    "g6e.4xlarge": 3.00424,
    "g6e.8xlarge": 4.52856,
    "g6e.12xlarge": 10.49264,
    "g6e.16xlarge": 7.57719,
    "g6e.24xlarge": 15.06559,
    "g6e.48xlarge": 30.13118,
    "p4d.24xlarge": 11.79166,
    "p4de.24xlarge": 14.75,
    "p5.48xlarge": 31.45833,
    "p5e.48xlarge": 34.625,
    "p5en.48xlarge": 36.16666,
    "p6-b200.48xlarge": 65.125,
    "H20-141G": 48.618
  },
  "default_region": "us-east-1",
  "last_updated": "2025-01-30",
  "notes": {
    "g6e": "NVIDIA L40s GPU instances - good for inference workloads",
    "p4d": "NVIDIA A100 GPU instances - high performance training and inference",
    "p4de": "NVIDIA A100 GPU instances - high performance training and inference",
    "p5": "NVIDIA H100 GPU instances - latest generation for AI workloads",
    "p5en": "NVIDIA H200 GPU instances with enhanced networking",
    "p6-b200": "NVIDIA B200 GPU instances - next generation AI accelerators"
  }
}